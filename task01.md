# 【Datawhale AI 夏令营】基于术语词典干预的机器翻译挑战赛_01
# Task_01
作为一名nlp小白，首先参考了夏令营提供的task，以及跑通了给出的baseline，难度不大。同时，在此基础上能够初步了解nlp、机器翻译的原理才是重头。

# 首先，对于机器翻译的历史，这里就不再赘述了，以下是简单总结：
    
    1. 基于规则的机器翻译（1950s-1980s）：利用语言学家编写的语法规则和词典进行翻译 （早期方法）
    2. 基于统计的机器翻译（1990s-2000s）：通过分析大量双语文本，自动学习源语言和目标语言之间的对应关系，从而实现翻译。
    3. 基于神经网络机器翻译（2010s-present）：近年来，深度学习技术的快速发展推动了神经网络机器翻译（Neural Machine Translation，简称NMT）的兴起。NMT使用深度神经网络模型，如长短期记忆网络（LSTM）和 Transformer，能够自动学习源语言和目标语言之间的复杂映射关系，无需人工设计特征或规则。
    4. 未来发展趋势：多模态、跨语言信息检索等是研究热点。

# Baseline部分： 针对本次baseline，其算法是基于pytorch的seq2seq机器翻译模型，序列到序列模型常用于机器翻译
# 赛题解析：依据赛事方提供的双语数据，实现以英文作为输入数据，中文作为目标语言的机器翻译。
# 赛题数据：
    - 训练集：双语数据 - 中英14万余双语句对
    - 开发集：英中1000双语句对
    - 测试集：英中1000双语句对
    - 术语词典：英中2226条

# 评价指标
## BLEU-4指标
    BLEU，全称为Bilingual Evaluation Understudy（双语评估替换），是一种对生成语句进行评估的指标。BLEU 评分是由Kishore Papineni等人2002年的论文《BLEU: a Method for Automatic Evaluation of Machine Translation》中提出的。
    BLEU是一种常用的自动评价指标，用于衡量计算机生成的翻译与一组参考译文之间的相似度。这个指标特别关注 n-grams（连续的n个词）的精确匹配，可以被认为是对翻译准确性和流利度的一种统计估计。
    计算BLEU分数时，首先会统计生成文本中n-grams的频率，然后将这些频率与参考文本中的n-grams进行比较。
    如果生成的翻译中包含的n-grams与参考译文中出现的相同，则认为是匹配的。最终的BLEU分数是一个介于0到1之间的数值，其中1表示与参考译文完美匹配，而0则表示完全没有匹配。
    BLEU-4 特别指的是在计算时考虑四元组（即连续四个词）的匹配情况。
    除了翻译之外，BLEU评分结合深度学习方法可应用于其他的语言生成问题，例如：语言生成、图片标题生成、文本摘要、语音识别。
